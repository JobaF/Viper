{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 14.2 s, total: 1min 51s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "# Define the Filepath for the Dataset\n",
    "filepath = 'OPENDATA_BOOKING_CALL_A_BIKE.csv'\n",
    "\n",
    "# Define the Chunksize\n",
    "chunksize = 10 ** 6\n",
    "\n",
    "# Define the specific Timerange \n",
    "date_after = pd.Timestamp('2013-12-31 23:59:59')\n",
    "date_before = pd.Timestamp('2016-01-01 00:00:00')\n",
    "\n",
    "# Define the Columns that contain Dates\n",
    "dates_from_data = ['DATE_BOOKING',\n",
    "                   'DATE_FROM',\n",
    "                   'DATE_UNTIL']\n",
    "\n",
    "# Define the columns that are needed from the Dataset\n",
    "needed_cols = ['DATE_BOOKING' ,\n",
    "               'DATE_FROM',\n",
    "               'DATE_UNTIL',\n",
    "               'START_RENTAL_ZONE',\n",
    "               'END_RENTAL_ZONE',\n",
    "               'CITY_RENTAL_ZONE']\n",
    "\n",
    "# Definition that imports the Cataset in Chunks of 1,000,000 rows to not clog the Memory\n",
    "def load_csv():\n",
    "    \n",
    "    data_iterator = pd.read_csv(filepath,\n",
    "                                chunksize=chunksize,\n",
    "                                sep=';',\n",
    "                                parse_dates=dates_from_data,\n",
    "                                usecols=needed_cols)\n",
    "    chunk_list = []  \n",
    "\n",
    "    # Each chunk is in dataframe format\n",
    "    for data_chunk in data_iterator:  \n",
    "        # Filter the Data for the City Hamburg and the given Time Horizon\n",
    "        filtered_chunk = data_chunk[(data_chunk['CITY_RENTAL_ZONE'] == 'Hamburg') &\n",
    "                                    (data_chunk['DATE_UNTIL'] > date_after) &\n",
    "                                    (data_chunk['DATE_UNTIL'] < date_before)]\n",
    "        # Append the chunk into a list, so we have the continued data\n",
    "        chunk_list.append(filtered_chunk)\n",
    "    filtered_data = pd.concat(chunk_list)\n",
    "    return filtered_data\n",
    "\n",
    "# Time how long it takes to load the Bike Dataset and insert it into the bike_data variable\n",
    "%time bike_data = load_csv()\n",
    "\n",
    "# Format the Dates from Object to DateTime Types\n",
    "bike_data['DATE_BOOKING'] = pd.to_datetime(bike_data['DATE_BOOKING'],\n",
    "                                                        format='%Y%m%d %H:%M:%S')\n",
    "bike_data['DATE_FROM'] = pd.to_datetime(bike_data['DATE_FROM'],\n",
    "                                                        format='%Y%m%d %H:%M:%S')\n",
    "bike_data['DATE_UNTIL'] = pd.to_datetime(bike_data['DATE_UNTIL'],\n",
    "                                                        format='%Y%m%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_BOOKING</th>\n",
       "      <th>DATE_FROM</th>\n",
       "      <th>DATE_UNTIL</th>\n",
       "      <th>START_RENTAL_ZONE</th>\n",
       "      <th>END_RENTAL_ZONE</th>\n",
       "      <th>CITY_RENTAL_ZONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-01 00:34:54</td>\n",
       "      <td>2014-01-01 00:34:54</td>\n",
       "      <td>2014-01-01 00:50:14</td>\n",
       "      <td>U-Bahn Baumwall</td>\n",
       "      <td>Mönckebergstraße / Rosenstraße</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01 01:39:55</td>\n",
       "      <td>2014-01-01 01:39:55</td>\n",
       "      <td>2014-01-01 01:57:27</td>\n",
       "      <td>Bahnhof Altona Ost/Max-Brauer-Allee</td>\n",
       "      <td>Schulterblatt/Eifflerstraße</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2014-01-01 01:40:20</td>\n",
       "      <td>2014-01-01 01:40:20</td>\n",
       "      <td>2014-01-01 01:53:09</td>\n",
       "      <td>Weidestraße/Biedermannplatz</td>\n",
       "      <td>Jarrestraße / Rambatzweg</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-01 01:56:00</td>\n",
       "      <td>2014-01-01 01:56:00</td>\n",
       "      <td>2014-01-01 01:56:41</td>\n",
       "      <td>Große Bergstraße / Jessenstraße</td>\n",
       "      <td>Große Bergstraße / Jessenstraße</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-01 02:05:55</td>\n",
       "      <td>2014-01-01 02:05:55</td>\n",
       "      <td>2014-01-01 02:13:49</td>\n",
       "      <td>Mundsburg / Schürbeker Straße</td>\n",
       "      <td>Bartholomäusstraße/Beim Alten Schützenhof</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8915006</td>\n",
       "      <td>2015-12-31 23:15:08</td>\n",
       "      <td>2015-12-31 23:15:08</td>\n",
       "      <td>2015-12-31 23:36:53</td>\n",
       "      <td>Löwenstraße/Eppendorfer Weg</td>\n",
       "      <td>Schulterblatt/Eifflerstraße</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8915007</td>\n",
       "      <td>2015-12-31 23:28:26</td>\n",
       "      <td>2015-12-31 23:28:26</td>\n",
       "      <td>2015-12-31 23:43:06</td>\n",
       "      <td>Lortzingstraße/Friedrichsberger Straße</td>\n",
       "      <td>Eduard-Rhein-Ufer / Schwanenwik</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8915076</td>\n",
       "      <td>2015-12-31 22:40:18</td>\n",
       "      <td>2015-12-31 22:40:18</td>\n",
       "      <td>2015-12-31 22:48:34</td>\n",
       "      <td>Hohenzollernring/Friedensallee</td>\n",
       "      <td>Bahnhof Altona West / Busbahnhof</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8915078</td>\n",
       "      <td>2015-12-31 23:37:41</td>\n",
       "      <td>2015-12-31 23:37:41</td>\n",
       "      <td>2015-12-31 23:47:13</td>\n",
       "      <td>Burgstraße/Hammer Landstraße</td>\n",
       "      <td>Alsterschwimmhalle/Ifflandstraße</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8915157</td>\n",
       "      <td>2015-12-31 22:08:26</td>\n",
       "      <td>2015-12-31 22:08:26</td>\n",
       "      <td>2015-12-31 22:33:32</td>\n",
       "      <td>Siemersplatz/Kollaustraße</td>\n",
       "      <td>Sternschanze / Eingang Dänenweg</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4967144 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DATE_BOOKING           DATE_FROM          DATE_UNTIL  \\\n",
       "0       2014-01-01 00:34:54 2014-01-01 00:34:54 2014-01-01 00:50:14   \n",
       "1       2014-01-01 01:39:55 2014-01-01 01:39:55 2014-01-01 01:57:27   \n",
       "2       2014-01-01 01:40:20 2014-01-01 01:40:20 2014-01-01 01:53:09   \n",
       "3       2014-01-01 01:56:00 2014-01-01 01:56:00 2014-01-01 01:56:41   \n",
       "4       2014-01-01 02:05:55 2014-01-01 02:05:55 2014-01-01 02:13:49   \n",
       "...                     ...                 ...                 ...   \n",
       "8915006 2015-12-31 23:15:08 2015-12-31 23:15:08 2015-12-31 23:36:53   \n",
       "8915007 2015-12-31 23:28:26 2015-12-31 23:28:26 2015-12-31 23:43:06   \n",
       "8915076 2015-12-31 22:40:18 2015-12-31 22:40:18 2015-12-31 22:48:34   \n",
       "8915078 2015-12-31 23:37:41 2015-12-31 23:37:41 2015-12-31 23:47:13   \n",
       "8915157 2015-12-31 22:08:26 2015-12-31 22:08:26 2015-12-31 22:33:32   \n",
       "\n",
       "                              START_RENTAL_ZONE  \\\n",
       "0                               U-Bahn Baumwall   \n",
       "1           Bahnhof Altona Ost/Max-Brauer-Allee   \n",
       "2                   Weidestraße/Biedermannplatz   \n",
       "3               Große Bergstraße / Jessenstraße   \n",
       "4                 Mundsburg / Schürbeker Straße   \n",
       "...                                         ...   \n",
       "8915006             Löwenstraße/Eppendorfer Weg   \n",
       "8915007  Lortzingstraße/Friedrichsberger Straße   \n",
       "8915076          Hohenzollernring/Friedensallee   \n",
       "8915078            Burgstraße/Hammer Landstraße   \n",
       "8915157               Siemersplatz/Kollaustraße   \n",
       "\n",
       "                                   END_RENTAL_ZONE CITY_RENTAL_ZONE  \n",
       "0                   Mönckebergstraße / Rosenstraße          Hamburg  \n",
       "1                      Schulterblatt/Eifflerstraße          Hamburg  \n",
       "2                         Jarrestraße / Rambatzweg          Hamburg  \n",
       "3                  Große Bergstraße / Jessenstraße          Hamburg  \n",
       "4        Bartholomäusstraße/Beim Alten Schützenhof          Hamburg  \n",
       "...                                            ...              ...  \n",
       "8915006                Schulterblatt/Eifflerstraße          Hamburg  \n",
       "8915007            Eduard-Rhein-Ufer / Schwanenwik          Hamburg  \n",
       "8915076           Bahnhof Altona West / Busbahnhof          Hamburg  \n",
       "8915078           Alsterschwimmhalle/Ifflandstraße          Hamburg  \n",
       "8915157            Sternschanze / Eingang Dänenweg          Hamburg  \n",
       "\n",
       "[4967144 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEMPERATURE DATA STATIONS FOR 'HAMBURG'\n",
    "#00954 UFS Deutsche Bucht    -- geoBreite = 54.1796   geoLaenge = 7.4587 This is in the Nordsee and can't be used to the city hamburg\n",
    "#01228 UFS TW Ems            -- geoBreite = 54.1651   geoLaenge = 6.3460 Same as above\n",
    "#01975 Hamburg-Fühlsbüttel   -- geoBreite = 53.6332   geoLaenge = 9.9881\n",
    "#01981 Hamburg-Neuwiedenthal -- geoBreite = 53.4777   geoLaenge = 9.8957\n",
    "#06254 Hamburg-Lotsenhöft    -- not available\n",
    "#13904 Nordseeboje 2         -- only till 2010\n",
    "\n",
    "#TODO GET GOOGLE MAPS COORDINATES WITH PICTURES https://www.gpskoordinaten.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filepath for the Temperature Data derived from the German Weather Service Data (DWD)\n",
    "filepath_temperature_dict = ['temperature_station_01975.csv', 'temperature_station_01981.csv']\n",
    "\n",
    "# Read the .csv files from the stations 1975 and 1981\n",
    "temperature_station_1975 = pd.read_csv(filepath_temperature_dict[0], sep=';',\n",
    "                                       usecols=['STATIONS_ID','MESS_DATUM','TT_TU'])\n",
    "temperature_station_1981 = pd.read_csv(filepath_temperature_dict[1], sep=';',\n",
    "                                       usecols=['STATIONS_ID','MESS_DATUM','TT_TU'])\n",
    "\n",
    "# Rename the columns to clearly know what they stand for\n",
    "temperature_station_1975.columns = ['ID', 'DATE', 'TEMPERATURE']\n",
    "temperature_station_1981.columns = ['ID', 'DATE', 'TEMPERATURE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data missing for station 1975!\n",
      "No data missing for station 1981!\n"
     ]
    }
   ],
   "source": [
    "# Format the Dates from Object to DateTime Types\n",
    "temperature_station_1975['DATE'] = pd.to_datetime(temperature_station_1975['DATE'],\n",
    "                                                        format='%Y%m%d%H')\n",
    "temperature_station_1981['DATE'] = pd.to_datetime(temperature_station_1981['DATE'],\n",
    "                                                        format='%Y%m%d%H')\n",
    "\n",
    "\n",
    "# Filter for the Data from 2014-2015\n",
    "temperature_station_1975 = temperature_station_1975[(temperature_station_1975['DATE'] > date_after) \n",
    "                                                    &\n",
    "                                                    (temperature_station_1975['DATE'] < date_before)]\n",
    "\n",
    "temperature_station_1981 = temperature_station_1981[(temperature_station_1981['DATE'] > date_after) \n",
    "                                                    & \n",
    "                                                    (temperature_station_1981['DATE'] < date_before)]\n",
    "\n",
    "# Reset the Indices so that we start at 0\n",
    "temperature_station_1975.reset_index(drop=True, inplace=True)\n",
    "temperature_station_1981.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Check if we have all Data from the two Years (2 years * 365 days * 24 hours/day)\n",
    "if len(temperature_station_1975) == (2 * 365 * 24):\n",
    "    print('No data missing for station 1975!')\n",
    "if len(temperature_station_1981) == (2 * 365 * 24):\n",
    "    print('No data missing for station 1981!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute values missing for station 1975 are:  0\n",
      "Absolute values missing for station 1981 are:  1\n"
     ]
    }
   ],
   "source": [
    "# Check for missing Values\n",
    "print('Absolute values missing for station 1975 are: '\n",
    "      ,temperature_station_1975['TEMPERATURE'][temperature_station_1975['TEMPERATURE'] == -999.0].count())\n",
    "\n",
    "print('Absolute values missing for station 1981 are: '\n",
    "      ,temperature_station_1981['TEMPERATURE'][temperature_station_1981['TEMPERATURE'] == -999.0].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-82cff36c9884>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-82cff36c9884>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    temperature_station_1981.at[index_of_missing_value, 'TEMPERATURE'] =\u001b[0m\n\u001b[0m                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Handle missing Values by just using the other Stations Data at that exact Time \n",
    "# (obviously only works if the other Station has all the Data)\n",
    "\n",
    "index_of_missing_value = temperature_station_1981.index[temperature_station_1981['TEMPERATURE'] ==-999.0]\n",
    "\n",
    "temperature_station_1981.at[index_of_missing_value, 'TEMPERATURE'] = \n",
    "temperature_station_1975.loc[index_of_missing_value].TEMPERATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the difference between the two station to check,\n",
    "# if we should take just one station for simplicity or take a mean of the two\n",
    "check_station_differences = \n",
    "temperature_station_1975['TEMPERATURE'].subtract(temperature_station_1981['TEMPERATURE'])\n",
    "check_station_differences.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_station_differences.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values are too far from each other in their maxima (>5 degrees)\n",
    "# So we will complete the temperature data by taking the average of each station\n",
    "temperature_data = pd.DataFrame({'DATE' : temperature_station_1975['DATE'],\n",
    "                                 'TEMPERATURE': (temperature_station_1975['TEMPERATURE']\n",
    "                                                 +temperature_station_1975['TEMPERATURE'])/2})\n",
    "\n",
    "temperature_data['TEMPERATURE'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precipitation Data\n",
    "\n",
    "# Define the Filepath for Stations 1975 and 1981\n",
    "filepath_precipitation_dict = ['precipitation_station_01975.csv','precipitation_station_01981.csv']\n",
    "\n",
    "# Read the .csv files from the stations 1975 and 1981\n",
    "precipitation_station_1975 = pd.read_csv(filepath_precipitation_dict[0], sep=';', usecols=[0,1,3])\n",
    "precipitation_station_1981 = pd.read_csv(filepath_precipitation_dict[1], sep=';', usecols=[0,1,3])\n",
    "\n",
    "# Rename the columns to clearly know what they stand for\n",
    "precipitation_station_1975.columns = ['ID','DATE','PRECIPITATION']\n",
    "precipitation_station_1981.columns = ['ID','DATE','PRECIPITATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format the Dates from Object to DateTime Types\n",
    "precipitation_station_1975['DATE'] = pd.to_datetime(precipitation_station_1975['DATE'], format='%Y%m%d%H')\n",
    "precipitation_station_1981['DATE'] = pd.to_datetime(precipitation_station_1981['DATE'], format='%Y%m%d%H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for the Data from 2014-2015\n",
    "precipitation_station_1975 = precipitation_station_1975[(precipitation_station_1975['DATE'] > date_after) \n",
    "                                                        &\n",
    "                                                        (precipitation_station_1975['DATE'] < date_before)]\n",
    "precipitation_station_1981 = precipitation_station_1981[(precipitation_station_1981['DATE'] > date_after)\n",
    "                                                        & \n",
    "                                                        (precipitation_station_1981['DATE'] < date_before)]\n",
    "\n",
    "#Reset indices\n",
    "precipitation_station_1975.reset_index(drop=True, inplace=True)\n",
    "precipitation_station_1981.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print('Absolute values missing for station 1975 are: ',\n",
    "      precipitation_station_1975['PRECIPITATION'][precipitation_station_1975['PRECIPITATION'] == -999.0].count())\n",
    "print('Absolute values missing for station 1981 are: ',\n",
    "      precipitation_station_1981['PRECIPITATION'][precipitation_station_1981['PRECIPITATION'] == -999.0].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing value by just using the other stations data at that exact time\n",
    "index_of_missing_value = precipitation_station_1975.index[precipitation_station_1975['PRECIPITATION'] ==-999.0]\n",
    "value = precipitation_station_1981.loc[index_of_missing_value]['PRECIPITATION']\n",
    "precipitation_station_1975.at[index_of_missing_value, 'PRECIPITATION'] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we handled all the missing values\n",
    "\n",
    "print('Absolute values missing for station 1975 are: ',\n",
    "      precipitation_station_1975['PRECIPITATION'][precipitation_station_1975['PRECIPITATION'] == -999.0].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the count of the two datasets\n",
    "print(len(precipitation_station_1975),len(precipitation_station_1981))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to merge the datasets because both have missing hours (!=17520 values) \n",
    "precipitation_merge = pd.merge(precipitation_station_1975, precipitation_station_1981, on='DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the precipitation DataFrame from the merged data\n",
    "precipitation_data = pd.DataFrame({'DATE' : precipitation_merge['DATE'], \n",
    "                                   'PRECIPITATION' : (precipitation_merge['PRECIPITATION_x']\n",
    "                                                      +\n",
    "                                                      precipitation_merge['PRECIPITATION_y'])/2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the precipitation by the hour in mm, so we know what we are dealing with\n",
    "plt.plot(precipitation_data['DATE'], precipitation_data['PRECIPITATION'])\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Precipitation in mm/h')\n",
    "plt.title('Hourly Precipitation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.index = bike_data.DATE_BOOKING\n",
    "monthly_data_bike = []\n",
    "\n",
    "for i in range(1,13):\n",
    "    monthly_data_bike.append([i,bike_data['DATE_BOOKING'].loc[(bike_data['DATE_BOOKING'].dt.month) == i].count()])\n",
    "\n",
    "monthly_data_bike = pd.DataFrame(monthly_data_bike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "monthly_data_bike.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Bookings per Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(monthly_data_bike[0],monthly_data_bike[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayofweek_data_bike = []\n",
    "\n",
    "for i in range(0,7):\n",
    "    dayofweek_data_bike.append([i,bike_data['DATE_BOOKING'].loc[(bike_data['DATE_BOOKING'].dt.dayofweek) == i].count()])\n",
    "\n",
    "dayofweek_data_bike = pd.DataFrame(dayofweek_data_bike)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dayofweek_data_bike.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dayofweek_data_bike[1].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike bookings per day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(dayofweek_data_bike[0],dayofweek_data_bike[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourofday_data_bike = []\n",
    "\n",
    "for i in range(0,24):\n",
    "    hourofday_data_bike.append([i,bike_data['DATE_BOOKING'].loc[(bike_data['DATE_BOOKING'].dt.hour) == i].count()])\n",
    "\n",
    "hourofday_data_bike = pd.DataFrame(hourofday_data_bike)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hourofday_data_bike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike bookings per hour of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(hourofday_data_bike[0],hourofday_data_bike[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data['TIME_BOOKED'] = bike_data['DATE_UNTIL'] - bike_data['DATE_FROM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.TIME_BOOKED.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time_booked = bike_data.TIME_BOOKED\n",
    "time_booked.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_booked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourofday_data_time = []\n",
    "\n",
    "def integer_to_time_hour(a):\n",
    "    if a < 10:\n",
    "        output = str('0'+str(a)+':00')\n",
    "    else:\n",
    "        output = str(str(a)+':00')\n",
    "    return output\n",
    "    \n",
    "for i in range(0,24):\n",
    "    hourofday_data_time.append([integer_to_time_hour(i),time_booked.loc[(bike_data['DATE_BOOKING'].dt.hour) == i].mean()/ datetime.timedelta(minutes=1)])\n",
    "\n",
    "hourofday_data_time = pd.DataFrame(hourofday_data_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hourofday_data_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average length of booking in minutes per hour of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(hourofday_data_time.index,hourofday_data_time[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayofweek_data_time = []\n",
    "\n",
    "for i in range(0,7):\n",
    "    dayofweek_data_time.append([i,time_booked.loc[(bike_data['DATE_BOOKING'].dt.dayofweek) == i].mean()\n",
    "                                / datetime.timedelta(minutes=1)])\n",
    "\n",
    "dayofweek_data_time = pd.DataFrame(dayofweek_data_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayofweek_data_time[2] = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "dayofweek_data_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average length of booking per day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(dayofweek_data_time[2],dayofweek_data_time[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monthly_data_time = []\n",
    "\n",
    "for i in range(1,13):\n",
    "    monthly_data_time.append([i,time_booked.loc[(bike_data['DATE_BOOKING'].dt.month) == i].mean()\n",
    "                             / datetime.timedelta(minutes=1)])\n",
    "\n",
    "monthly_data_time = pd.DataFrame(monthly_data_time)\n",
    "\n",
    "monthly_data_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average length of booking per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(monthly_data_time[0],monthly_data_time[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean start time day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_booked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Booking Start Time per Week (in hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dayofweek_mean = []\n",
    "daysofweek = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "for i in range(0,7):\n",
    "    dayofweek_mean.append(bike_data['DATE_FROM'].loc[(bike_data['DATE_FROM'].dt.dayofweek) == i])\n",
    "\n",
    "dayofweek_averages = []\n",
    "avg = 0\n",
    "\n",
    "for i in range(0,7):\n",
    "    for elem in dayofweek_mean[i]:\n",
    "        avg += (elem.hour*3600+elem.minute*60+elem.second)\n",
    "    dayofweek_averages.append(avg/len(dayofweek_mean[i])/60/60)\n",
    "    avg = 0\n",
    "\n",
    "dayofweek_averages = pd.Series(dayofweek_averages)\n",
    "\n",
    "plt.bar(daysofweek, dayofweek_averages)\n",
    "plt.axis([-0.5,6.5,13.5, 15])\n",
    "plt.title('Average start time per week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Start Time per Month (in hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_mean = []\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "for i in range(1,13):\n",
    "    monthly_mean.append(bike_data['DATE_FROM'].loc[(bike_data['DATE_FROM'].dt.month) == i])\n",
    "\n",
    "monthly_averages = []\n",
    "avg = 0\n",
    "\n",
    "for i in range(0,12):\n",
    "    for elem in monthly_mean[i]:\n",
    "        avg += (elem.hour*3600+elem.minute*60+elem.second)\n",
    "    monthly_averages.append(avg/len(monthly_mean[i])/60/60)\n",
    "    avg = 0\n",
    "\n",
    "monthly_averages = pd.Series(monthly_averages)\n",
    "\n",
    "plt.bar(months, monthly_averages)\n",
    "plt.axis([-0.5,12,13.5, 15])\n",
    "plt.title('Average start time per month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'DATE' : pd.date_range(start='1/1/2014', end='31/12/2015 23:00:00', freq='H')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = data.DATE\n",
    "temperature_data.index = temperature_data['DATE']\n",
    "precipitation_data.index = precipitation_data['DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data['TEMPERATURE'] = temperature_data['TEMPERATURE']\n",
    "data['PRECIPITATION'] = precipitation_data['PRECIPITATION']\n",
    "data['BOOKING_COUNT'] = hourly_bike_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
